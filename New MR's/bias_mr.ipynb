{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metamorphic Relation to calculate bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation using Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 30, 30, 3)\n",
      "WARNING:tensorflow:From /home/razorback/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 31368 samples, validate on 7841 samples\n",
      "31368/31368 [==============================] - 141s 5ms/sample - loss: 1.2049 - acc: 0.6631 - val_loss: 0.1435 - val_acc: 0.9621\n"
     ]
    }
   ],
   "source": [
    "#Importing model, training data set and validation data set from the CNN_classifier provided\n",
    "from cnn_classifier import model, X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31368 samples, validate on 7841 samples\n",
      "Epoch 1/2\n",
      "31368/31368 [==============================] - 295s 9ms/sample - loss: 0.2415 - acc: 0.9288 - val_loss: 0.0580 - val_acc: 0.9843\n",
      "Epoch 2/2\n",
      "31368/31368 [==============================] - 246s 8ms/sample - loss: 0.1604 - acc: 0.9510 - val_loss: 0.0468 - val_acc: 0.9856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f36bc609a20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=2, \n",
    "          validation_data=(X_val, y_val), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e3251d519d609f64\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e3251d519d609f64\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Bias and Fairness of our model using Google What-if tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Help is taken from the notebook demo of WIT Smile Detector.ipynb to develop this code for my purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from witwidget.notebook.visualization import WitWidget, WitConfigBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_examples(df, columns=None, images_path=''):\n",
    "    examples = []\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for index, row in df.iterrows():\n",
    "        example = tf.train.Example()\n",
    "    for col in columns:\n",
    "        if df[col].dtype is np.dtype(np.int64):\n",
    "            example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "        elif df[col].dtype is np.dtype(np.float64):\n",
    "            example.features.feature[col].float_list.value.append(row[col])\n",
    "        elif row[col] == row[col]:\n",
    "            example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "    if images_path:\n",
    "        fname = row['Path']\n",
    "        with open(os.path.join(images_path, fname), 'rb') as f:\n",
    "            im = Image.open(f)\n",
    "            buf = BytesIO()\n",
    "            im.save(buf, format= 'PNG')\n",
    "            im_bytes = buf.getvalue()\n",
    "            example.features.feature['image/encoded'].bytes_list.value.append(im_bytes)\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "def make_label_column_numeric(df, label_column, test):\n",
    "    df[label_column] = np.where(test(df[label_column]), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load the csv file into pandas dataframe and process it for WIT\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r'/home/razorback/BTP/metamorphic_testing/traffic/gtsrb-german-traffic-sign/Train.csv')\n",
    "data['image_id'] = range(1, len(data)+1)\n",
    "path = r'/home/razorback/BTP/metamorphic_testing/traffic/gtsrb-german-traffic-sign/'\n",
    "examples = df_to_examples(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_predict(examples_to_infer):\n",
    "    def load_byte_img(im_bytes):\n",
    "        buf = BytesIO(im_bytes)\n",
    "        return np.array(Image.open(buf), dtype=np.float64) / 255.\n",
    "\n",
    "    ims = [load_byte_img(ex.features.feature['image/encoded'].bytes_list.value[0]) \n",
    "         for ex in examples_to_infer]\n",
    "    preds = model.predict(np.array(ims))\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_datapoints = 250  \n",
    "tool_height_in_px = 700 \n",
    "\n",
    "# Decode an image from tf.example bytestring\n",
    "def decode_image(ex):\n",
    "    im_bytes = ex.features.feature['image/encoded'].bytes_list.value[0]\n",
    "    im = Image.open(BytesIO(im_bytes))\n",
    "    return im\n",
    "\n",
    "# Define the custom distance function that compares the average color of images\n",
    "def image_mean_distance(ex, exs, params):\n",
    "    selected_im = decode_image(ex)\n",
    "    mean_color = np.mean(selected_im, axis=(0,1))\n",
    "    image_distances = [np.linalg.norm(mean_color - np.mean(decode_image(e), axis=(0,1))) for e in exs]\n",
    "    return image_distances\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(examples[:num_datapoints]).set_custom_predict_fn(\n",
    "    custom_predict).set_custom_distance_fn(image_mean_distance)\n",
    "\n",
    "wv = WitWidget(config_builder, height=tool_height_in_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "badc06efa22149a984c6119a9fb82117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': [], 'inference_address': 'custom_predict_fn',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
